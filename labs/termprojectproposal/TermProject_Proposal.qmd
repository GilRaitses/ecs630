---
title: "Term Project Proposal: Stimulus-Driven Behavioral Modeling of Drosophila Larvae"
subtitle: "Event-Hazard Modeling of Turn Initiation and Trajectory Simulation"
author: "Gil Raitses"
date: today
abstract: |
  \tech{Behavioral responses} to \tech{time-varying stimuli} in \tech{Drosophila larvae} show \tech{temporal dynamics} with \tech{latency-dependent} and \tech{intensity-dependent} patterns. This project develops a \tech{stimulus-locked event-hazard model} for \tech{turn initiation} and \tech{run-stop transitions} using \tech{generalized linear models} with \tech{temporal kernel bases} that capture stimulus-response relationships. The model estimates time-varying hazard rates for behavioral events conditioned on \tech{stimulus intensity}, \tech{temporal history}, and \tech{contextual features} including speed, orientation, and wall proximity. Using a \tech{design of experiments} framework with \tech{stimulus intensity}, \tech{pulse duration}, and \tech{inter-pulse interval} as factors, the analysis generates \tech{simulated trajectories} that produce \tech{key performance indicators} including mean turn rate, latency to first turn, stop fraction, and spatial distribution metrics. \tech{Confidence intervals} for behavioral metrics provide statistical precision comparable to \tech{Arena simulation replications}, which supports validation of model predictions against empirical larval trajectory data.
format:
  pdf:
    documentclass: article
    geometry:
      - margin=1in
    fig-dpi: 300
    toc: false
    number-sections: true
    pdf-engine: lualatex
header-includes: |
  \usepackage{fontspec}
  \setmainfont{Avenir Next}[
    UprightFont = *-UltraLight,
    BoldFont = *-Medium,
    ItalicFont = *-UltraLightItalic,
    BoldItalicFont = *-MediumItalic
  ]
  \newfontfamily\headingfont{Didot}
  \newfontfamily\numfont{Avenir Next Regular}
  \newfontfamily\techfont{Avenir Next Medium}
  \usepackage{xcolor}
  \newcommand{\num}[1]{{\numfont\textcolor[gray]{0.3}{#1}}}
  \newcommand{\tech}[1]{{\techfont\textcolor[RGB]{105,100,100}{#1}}}
  \usepackage{sectsty}
  \allsectionsfont{\headingfont}
  \subsectionfont{\headingfont\itshape\color[RGB]{90,60,60}}
  \subsubsectionfont{\headingfont\itshape\color[RGB]{90,60,60}}
  \renewcommand{\thesubsection}{\hspace{-1em}}
  \renewcommand{\thesubsubsection}{\hspace{-1em}}
  \usepackage{tikz}
  \usetikzlibrary{shapes.geometric, arrows.meta, positioning, shadows}
  \usepackage{float}
  \usepackage{placeins}
  \usepackage{needspace}
  \usepackage{etoolbox}
  \usepackage{caption}
  \makeatletter
  \preto\section{\needspace{6\baselineskip}}
  \preto\subsection{\needspace{6\baselineskip}}
  \preto\subsubsection{\needspace{6\baselineskip}}
  \makeatother
  \captionsetup{margin=0.5in, font=small}
  \setlength{\floatsep}{1.5em}
  \setlength{\textfloatsep}{1.5em}
  \newenvironment{insetfigure}{\begin{adjustwidth}{0.5in}{0.5in}}{\end{adjustwidth}}
  \usepackage{changepage}
  \usepackage{amsmath}
  \usepackage{bm}
  \tikzstyle{process} = [regular polygon, regular polygon sides=6, minimum width=3.5cm, minimum height=2cm, text centered, text width=2.5cm, draw=black!80, fill=gray!20, line width=1.2pt, drop shadow]
  \tikzstyle{arrow} = [ultra thick,->,>=stealth, draw=black!70]
execute:
  python: /Users/gilraitses/ecs630/labs/lab01/venv/bin/python3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  dpi = 300
)

# Load required libraries
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(tidyr)
library(cowplot)
library(grid)
library(showtext)

# Add EB Garamond font
font_add(family = "EB Garamond", 
         regular = "~/Library/Fonts/EBGaramond12-Regular.otf")
showtext_auto()
```

# Introduction

This term project develops a \tech{stimulus-response modeling framework} for \tech{Drosophila larval behavior} using \tech{event-hazard methods} from \tech{survival analysis} and \tech{generalized linear models}. The project uses existing trajectory data from mechanosensation experiments to estimate time-varying hazard rates for behavioral events including turns, stops, and reversals conditioned on \tech{LED stimulus intensity}, \tech{temporal history}, and \tech{contextual features}. The model simulates trajectories under different \tech{experimental conditions} specified through a \tech{design of experiments} framework, which produces behavioral metrics comparable to empirical observations.

The project connects simulation modeling methods from \tech{ECS630} with biological data analysis. \tech{Discrete-event simulation principles} apply to \tech{behavioral systems} where events occur stochastically as functions of external stimuli and internal state. Results use \tech{Arena-style summary statistics} including \tech{across-replications summaries}, \tech{confidence intervals}, and \tech{performance metrics} analogous to manufacturing system analysis.

# Problem Statement

## Research Question

How can \tech{larval behavioral responses} to \tech{time-varying LED stimuli} be modeled using \tech{event-hazard methods} to predict \tech{turn initiation rates}, \tech{behavioral state transitions}, and \tech{trajectory-level statistics}?

## Dataset Characteristics

The mechanosensation dataset contains:

- **Trajectory Data**: Individual larval tracks with position coordinates, speeds, orientations, and behavioral events (runs, reorientations, head swings)
- **Stimulus Data**: LED intensity values synchronized to video frames, with stimulus onset times, pulse durations, and inter-pulse intervals
- **Experimental Conditions**: Multiple experiments with varying stimulus intensities (0-100\% LED power), pulse frequencies, and temporal patterns
- **Sample Size**: \num{40+} larvae per condition, multiple replications per experimental condition

## Modeling Challenge

Behavioral events occur stochastically with rates that depend on:
1. **Stimulus features**: Current intensity, recent history (adaptation/habituation), pulse timing
2. **Contextual features**: Current speed, orientation relative to stimulus source, distance to arena walls
3. **Individual heterogeneity**: Larva-to-larva variation in baseline activity and sensitivity

Traditional approaches use simple rate averages or linear regressions. This project develops a \tech{structured hazard model} that captures temporal dependencies and supports trajectory simulation.

# Proposed Methodology

## Core Model: Stimulus-Locked Event-Hazard GLM

For each behavioral event type $E \in \{\text{turn}, \text{stop}, \text{reverse}\}$, define the time-varying hazard rate:

$$\lambda_E(t) = \exp\left\{ \beta_{0,E} + \phi_E^\top [s \star \kappa](t) + \mathbf{x}(t)^\top \mathbf{\beta}_E \right\}$$

where:

- $\beta_{0,E}$: Baseline log-hazard for event type $E$
- $s(t)$: Stimulus feature vector (intensity, on/off state, recent history)
- $\kappa$: Temporal kernel (basis expansion capturing latency and adaptation)
- $[s \star \kappa](t)$: Convolution of stimulus with kernel (stimulus history features)
- $\mathbf{x}(t)$: Contextual features (speed, orientation, wall distance)
- $\mathbf{\beta}_E$: Feature coefficients

### Temporal Kernel Design

The kernel $\kappa(\tau)$ captures:
- **Latency effects**: Peak response at delay $\tau_0 \approx 0.5-2$ seconds
- **Adaptation**: Decay over longer delays ($\tau > 5$ seconds)
- **Anticipation**: Pre-stimulus effects (if any)

Using raised cosine basis functions:
$$\kappa(\tau) = \sum_{j=1}^{J} w_j \cos^2\left(\frac{\pi(\tau - \tau_j)}{2\Delta\tau}\right) \mathbf{1}_{[\tau_j-\Delta\tau, \tau_j+\Delta\tau]}(\tau)$$

with knots $\tau_j$ spanning $[-2, 20]$ seconds relative to stimulus onset.

### Event Likelihood and Estimation

For larva $i$ with observed events at times $\{t_{i,k}\}$, the log-likelihood is:

$$\ell(\mathbf{\beta}) = \sum_i \sum_k \log \lambda_E(t_{i,k}) - \int_0^{T_i} \lambda_E(t) dt$$

Estimation via \tech{penalized maximum likelihood} with $L_2$ regularization:

$$\hat{\mathbf{\beta}} = \arg\max \left\{ \ell(\mathbf{\beta}) - \lambda_{\text{reg}} \|\mathbf{\beta}\|_2^2 \right\}$$

### Model Validation

Model validation uses three methods. The time-rescaled KS test transforms observed event times $t_k \to \int_0^{t_k} \lambda_E(t) dt$, which under the correct model should form Poisson process increments. Predictive log-likelihood evaluates holdout larvae for each experimental condition. Peri-stimulus time histograms compare model-predicted versus observed event rates around stimulus onsets.

## Trajectory Simulation

Given a fitted hazard model, the simulation follows five steps. Initialization samples starting position, orientation, and speed from empirical distributions. Event generation samples the next event time $t^*$ from $\lambda_E(t)$ using a thinning algorithm. Event execution handles turns by sampling new orientation, stops by pausing, and reversals by flipping direction. State update integrates position using forward Euler integration with current speed and orientation. The process repeats until reaching maximum simulation time.

### Speed Dynamics

Run speeds follow observed empirical distributions (typically log-normal). During runs, integrate:
$$\mathbf{x}(t+\Delta t) = \mathbf{x}(t) + v(t) \Delta t \cdot [\cos(\theta(t)), \sin(\theta(t))]^\top$$

where $v(t)$ is current speed and $\theta(t)$ is current heading.

## Design of Experiments

### Factors and Levels

| Factor | Levels | Description | Units |
|--------|--------|-------------|-------|
| Stimulus Intensity | 3 (PWM 250, 500, 1000) | Threshold, moderate, and high stimulus levels | PWM percentage |
| Pulse Duration | 5 (10s, 15s, 20s, 25s, 30s) | Short to extended stimulus presentations | Seconds |
| Inter-Pulse Interval | 3 (5s, 10s, 20s) | Rapid, moderate, and spaced stimulus timing | Seconds |

### Response Variables (KPIs)

1. **Turn Rate**: Reorientations per minute (reorientations/min)
2. **Latency to First Turn**: Time from stimulus onset to first turn (seconds)
3. **Stop Fraction**: Proportion of time spent stopped (dimensionless)
4. **Pause Rate**: Pauses per minute (pauses/min)
5. **Path Tortuosity**: Net displacement / path length (dimensionless)
6. **Spatial Dispersal**: Mean distance from starting position (pixels)
7. **Mean Spine Curve Energy**: Average curvature energy along body axis (dimensionless)

### Experimental Design

**Full factorial design**: $3 \times 5 \times 3 = 45$ conditions. For each condition:
- Run \num{30} simulation replications (each representing one larva)
- Record events and compute KPIs per replication
- Generate \tech{AcrossReplicationsSummary.csv} with means and confidence intervals

### Run Length Determination

The replication length follows Lab04 CI methodology. Target precision uses \num{10}\% relative half-width for mean turn rate, which means when the mean equals \num{5} turns per minute the confidence interval width stays below \num{0.5} turns per minute. A pilot study runs \num{10} replications to estimate variance $\hat{\sigma}^2$. Required replications follow $n \geq \left(\frac{z_{\alpha/2} \hat{\sigma}}{E}\right)^2$ where $E$ represents the desired half-width. When $n > 30$ the simulation uses that calculated value, while values $n \leq 30$ default to \num{30} replications as the minimum standard.

# Analysis Plan

## Data Preprocessing

### Input Data Sources

The primary data source uses H5 files containing exported MAGAT experiment data in HDF5 format such as `GMR61_202509051201_tier1.h5`. These files contain trajectory positions, LED stimulus data, and metadata located in `/Users/gilraitses/mechanosensation/h5tests/` and processed using `scripts/engineer_dataset_from_h5.py`. Backup sources include trajectory CSVs at `output/spatial_analysis/runs.csv` and `reorientations.csv`, stimulus CSVs with frame-level LED values in `led_stimulus_data_*.csv`, and experimental metadata with experiment IDs, conditions, and replication numbers.

### Feature Extraction

**Step 1: Extract from H5 Files**

```bash
python3 scripts/engineer_dataset_from_h5.py \
    --h5-dir /Users/gilraitses/mechanosensation/h5tests \
    --output-dir data/engineered \
    --experiment-id GMR61_202509051201
```

This creates:
- `{experiment_id}_events.csv`: Event records with 50ms time bins
- `{experiment_id}_trajectories.csv`: Full trajectory data aligned with stimulus
- `{experiment_id}_summary.json`: Summary statistics

**Step 2: Feature Engineering** (implemented in `engineer_dataset_from_h5.py`)

```python
# For each larva trajectory from H5:
for each track in h5_file['tracks']:
    # Extract positions (x, y) and compute derived features
    positions = track['positions']  # N×2 array
    speed = compute_speed(positions, frame_rate=20)
    heading = compute_heading(positions)
    heading_change = detect_turns(heading, threshold=30°)
    
    # Time-align with stimulus data
    stimulus_df = extract_stimulus_timing(h5_file['led_data'])
    aligned_df = align_trajectory_with_stimulus(trajectory_df, stimulus_df)
    
    # Create time bins (50ms)
    bin_width = 0.05
    binned = aggregate_to_bins(aligned_df, bin_width)
    
    # Create stimulus kernel features (in fit_hazard_model.py)
    for each bin:
        stimulus_history = extract_stimulus_window(time_window=[-2, 20])
        kernel_features = apply_temporal_kernel(stimulus_history, basis_functions)
        feature_vector = [kernel_features, speed, heading, wall_dist]
        event_occurred = (binned['is_turn'] == True)
```

### Model Fitting Pipeline

The model fitting pipeline consists of five steps. Event detection identifies turn starts, stop starts, and reversal starts from trajectory data. Feature matrix construction creates an $N \times P$ matrix where $N$ equals total time bins across all larvae and $P$ equals the number of features. GLM fitting uses `sklearn.linear_model.LogisticRegression` or `statsmodels` for Poisson GLM. Cross-validation applies leave-one-larva-out CV to assess generalization. Kernel visualization plots the fitted kernel $\hat{\kappa}(\tau)$ to interpret temporal response.

## Simulation and DOE Execution

### Simulation Engine

```python
class LarvalTrajectorySimulator:
    def __init__(self, hazard_model, speed_distribution, arena_bounds):
        self.hazard_model = hazard_model
        self.speed_dist = speed_distribution
        self.arena = arena_bounds
    
    def simulate(self, stimulus_schedule, max_time, random_seed):
        # Initialize state
        position = sample_starting_position()
        orientation = sample_starting_orientation()
        speed = self.speed_dist.sample()
        
        events = []
        t = 0
        
        while t < max_time:
            # Compute current hazard
            lambda_t = self.hazard_model.predict(
                stimulus=stimulus_schedule(t),
                speed=speed,
                orientation=orientation,
                wall_dist=compute_wall_distance(position)
            )
            
            # Sample next event time (thinning algorithm)
            next_event_time = sample_from_hazard(lambda_t, current_time=t)
            
            # Execute event
            if next_event_time < max_time:
                event_type = sample_event_type(lambda_t)  # turn, stop, reverse
                events.append((next_event_time, event_type))
                
                # Update state based on event
                if event_type == 'turn':
                    orientation = sample_new_orientation(orientation)
                elif event_type == 'stop':
                    speed = 0
                elif event_type == 'reverse':
                    orientation = flip_orientation(orientation)
            
            # Update position
            dt = min(next_event_time - t, 0.1)  # 100ms integration step
            position += speed * dt * [cos(orientation), sin(orientation)]
            t = next_event_time
        
        return Trajectory(position_history, events)
```

### DOE Execution

For each of 45 conditions:

```python
results = []
for condition in doe_table:
    for replication in range(30):
        # Set stimulus schedule from condition
        stimulus = create_stimulus_schedule(
            intensity=condition.intensity,
            pulse_duration=condition.pulse_duration,
            inter_pulse_interval=condition.inter_pulse_interval
        )
        
        # Simulate trajectory
        traj = simulator.simulate(stimulus, max_time=300, random_seed=replication)
        
        # Compute KPIs
        kpis = compute_kpis(traj)
        results.append({
            'condition': condition.id,
            'replication': replication,
            **kpis
        })

# Export to Arena-style CSV
export_to_arena_format(results, 'AcrossReplicationsSummary.csv')
```

## Statistical Analysis

### Performance Metrics Calculation

For each KPI and condition, the analysis calculates four statistics. The mean uses $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$. Standard deviation follows $s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2}$. The 95\% confidence interval uses $\bar{X} \pm t_{0.025,n-1} \frac{s}{\sqrt{n}}$. Minimum and maximum values track $\min_i X_i$ and $\max_i X_i$.

### Model Validation Metrics

Model validation uses four metrics. Holdout log-likelihood compares results to a null model with constant hazard. The KS test p-value evaluates whether time-rescaled event times follow a uniform distribution. PSTH correlation compares model-predicted versus observed peri-stimulus histograms. Trajectory-level statistics compare simulated versus empirical distributions of KPIs.

# Expected Deliverables

## Report Components

The report includes six components. Model specification covers mathematical formulation, kernel design, and estimation procedure. Data description presents dataset characteristics, preprocessing steps, and feature engineering. Model fitting results show fitted kernels, coefficients, and validation metrics. DOE results include AcrossReplicationsSummary tables, main effects, and interaction plots. Simulation validation compares simulated versus empirical KPIs. Confidence intervals explain CI construction methodology and run length justification.

## Supporting Files

Supporting files include four categories. Model code consists of Python scripts for fitting (`fit_hazard_model.py`), simulation (`simulate_trajectories.py`), and DOE execution (`run_doe.py`). Data exports produce Arena-style CSV files including `AcrossReplicationsSummary.csv`, `ContinuousTimeStatsByRep.csv`, and `DiscreteTimeStatsByRep.csv`. The DOE table stores 45 conditions and factor levels in `doe_table.csv`. Configuration uses `config.json` for model parameters, simulation settings, and CI targets.

## Format Requirements

Format requirements include four elements. The Quarto report uses `TermProject_Report.qmd` rendering to PDF. Style matches Lab01 and Lab02 formatting with Avenir Next body text, Didot headings, and technical terminology. Figures include kernel plots, PSTHs, KPI comparisons, and interaction plots. Tables include the DOE table, AcrossReplicationsSummary, and model coefficients.

# Timeline and Milestones

## Week 1: Data Preparation and Exploration

Week 1 loads and inspects trajectory and stimulus data, implements the feature extraction pipeline, and computes empirical KPIs for baseline conditions. The deliverable includes a data exploration notebook and baseline statistics.

## Week 2: Model Development

Week 2 implements temporal kernel basis functions, builds the GLM fitting pipeline, fits a baseline model with constant hazard, and assesses initial fit quality. The deliverable includes the fitted null model and kernel visualization code.

## Week 3: Hazard Model Fitting

Week 3 fits stimulus-locked hazard models for turns, stops, and reversals, performs cross-validation and hyperparameter tuning, and validates models using KS tests and PSTH comparisons. The deliverable includes fitted models and a validation report.

## Week 4: Simulation Engine Development

Week 4 implements the trajectory simulator, tests on simple stimulus schedules, and validates that simulated KPIs match empirical values for known conditions. The deliverable includes a working simulator and validation results.

## Week 5: DOE Execution and Analysis

Week 5 runs the full factorial design with 45 conditions and 30 replications per condition, generates AcrossReplicationsSummary CSVs, computes confidence intervals, and analyzes main effects and interactions. The deliverable includes complete DOE results and summary tables.

## Week 6: Report Writing and Finalization

Week 6 writes the Quarto report with all sections, generates figures and tables, and performs final model validation against holdout data. The deliverable includes the final report PDF and supporting code and data.

# Risk Assessment and Mitigation

## Technical Risks

Temporal alignment between stimulus and behavior data could be inaccurate. Mitigation uses validated synchronization methods through MAGAT `addTonToff`, implements unit tests for alignment, and visually inspects PSTHs for timing errors.

The model could overfit to training data with a complex kernel. Mitigation uses cross-validation, applies $L_2$ regularization, limits kernel complexity by reducing basis functions, and compares AIC/BIC across models.

Individual heterogeneity could violate the exchangeability assumption. Mitigation includes larva-specific random effects when needed, stratifies analysis by experimental batch, and uses hierarchical models when time permits.

Simulation might not capture spatial constraints such as wall interactions. Mitigation includes wall distance in the feature vector, implements boundary conditions in the simulator, and validates that spatial distributions match empirical data.

## Data Risks

Some experimental conditions might have insufficient data. Mitigation pools similar conditions, uses data augmentation through bootstrap resampling, and reports sample sizes per condition.

Trajectory segments could be missing or corrupted. Mitigation implements robust data validation, excludes problematic trajectories, and reports exclusion criteria in methods.

## Timeline Risks

Model fitting could take longer than expected. Mitigation starts with a simplified model using fewer features, uses existing GLM libraries, and parallelizes over larvae when needed.

Simulation could be computationally expensive for 1,350 total runs across 45 conditions with 30 replications each. Mitigation optimizes simulation code, runs overnight batches, uses cloud computing when needed, and reduces replications if CI targets are still met.

# Success Criteria

## Model Performance Targets

Model performance targets include three criteria. Predictive accuracy requires holdout log-likelihood improvement of at least \num{20}\% over the null model. Temporal fidelity requires a KS test p-value greater than \num{0.05}, which indicates the model is not rejected. Kernel interpretability requires the fitted kernel to show biologically plausible latency with peak response between 0.5 and 2 seconds.

## Simulation Validation Targets

Simulation validation targets include three criteria. KPI accuracy requires simulated mean turn rates to fall within the \num{95}\% CI of empirical values for baseline conditions. Distribution match requires simulated KPI distributions to pass a two-sample KS test versus empirical distributions with p-value greater than \num{0.05}. DOE consistency requires main effects to show expected signs such as higher intensity producing higher turn rate.

## Deliverable Quality Targets

Deliverable quality targets include three criteria. Report completeness requires all sections present with clear figures and tables and reproducible methods. Code quality requires well-documented scripts, configuration files, and unit tests where feasible. Data format requires CSVs to match Arena output format and remain readable by standard tools.

# Conclusion

This project applies \tech{simulation modeling methods} from \tech{ECS630} to \tech{biological behavioral data}, developing a \tech{stimulus-response model} that simulates larval trajectories under different experimental conditions. The \tech{event-hazard framework} models stochastic behavioral events, while the \tech{DOE methodology} explores stimulus parameter space systematically. Results use \tech{Arena-style statistics} including \tech{confidence intervals} and \tech{across-replications summaries}, which show how simulation principles extend from manufacturing systems to biological processes.

# Appendix

## Data Sources

- **Primary H5 Files**: `/Users/gilraitses/mechanosensation/h5tests/`
  - `GMR61_202509051201_tier1.h5` (16 MB): Complete experiment with tracks and LED data
  - `GMR61_tier2_complete.h5` (83 MB): Full tier2 export with contours
  - `GMR61_202509051201_tier3.h5` (701 KB): Tier3 export with FID data
- **Backup CSV Data**: `/Users/gilraitses/mechanosensation/output/spatial_analysis/`
- **Stimulus Data**: `/Users/gilraitses/mechanosensation/led_stimulus_data_*.csv` when needed
- **Experimental Metadata**: Experiment IDs embedded in H5 metadata or trajectory CSVs

## Model Implementation References

- **Survival Analysis**: Collett (2015) *Modelling Survival Data in Medical Research*
- **Point Process GLMs**: Berman & Turner (1992) "Approximating point process likelihoods with GLIM"
- **Temporal Kernels**: Pillow et al. (2008) "Spatio-temporal correlations and visual signalling"

## Software Tools

- **Python**: `scikit-learn`, `statsmodels`, `numpy`, `pandas` for modeling
- **R**: `ggplot2`, `knitr`, `kableExtra` for report generation
- **MATLAB**: MAGAT API for data loading when needed

